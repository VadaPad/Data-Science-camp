{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bd51d7",
   "metadata": {},
   "source": [
    "## Setting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51cc8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocessing(df):# Setting gender 1 - male, 0 female\n",
    "    df['Sex'] = df['Sex'].map({'male' : 1, 'female' : 0})\n",
    "    # Setting landing place Southampton - 1, Cherbourg - 2, Queenstown - 3\n",
    "    df['Embarked'] = df['Embarked'].map({'S' : 1, 'ะก' : 2, 'Q' : 3}).fillna(value = 1)\n",
    "    # Fill Nan values average values\n",
    "    df.fillna({'Age' : df['Age'].mean()}, inplace = True) \n",
    "    # Changing type columns to int64\n",
    "    df[['Age', 'Fare', 'Embarked']] = df[['Age', 'Fare', 'Embarked']].astype(int)\n",
    "    print('Preprocessing successfully completed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f263ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(df):\n",
    "# Setting gender 1 - male, 0 female\n",
    "    df['Sex'] = df['Sex'].map({'male' : 1, 'female' : 0}).fillna(1)\n",
    "    # Setting landing place Southampton - 1, Cherbourg - 2, Queenstown - 3\n",
    "    df['Embarked'] = df['Embarked'].map({'S' : 1, 'ะก' : 2, 'Q' : 3}).fillna(value = 1)\n",
    "    # Fill Nan values average values\n",
    "    df.fillna({'Age' : df['Age'].mean()}, inplace = True) \n",
    "    df.fillna({'Fare' : df['Fare'].mean()}, inplace = True)\n",
    "    # Changing type columns to int64\n",
    "    df[['Age', 'Fare', 'Embarked']] = df[['Age', 'Fare', 'Embarked']].astype(int)\n",
    "    print('Preprocessing successfully completed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae6946b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X_train X_test\n",
    "def normalize(X_train, X_test):\n",
    "    print ('normalizing.')\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('Preprocessing successfully completed')\n",
    "    return X_train_scaled, X_test_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1634986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running all classifiers\n",
    "def run_all_classifiers(X_train_scaled, X_test_scaled, y_train = None, y_test=None, list_classifiers= None):\n",
    "    if list_classifiers is None or 'LogisticRegression' in list_classifiers:\n",
    "        print ('\\nLogisticRegression.')\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        grid_values = {'C': [0.005, 0.01,0.1, 1, 100, 10000, 100000]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled,  y_train,  y_test= y_test)\n",
    "\n",
    "    if list_classifiers is None or 'DecisionTreeClassifier' in list_classifiers:\n",
    "        print ('\\nDecisionTreeClassifier')\n",
    "        clf = DecisionTreeClassifier()       \n",
    "        grid_values = {'max_depth': [2,5,7, 20, 50]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'RandomForestClassifier' in list_classifiers:\n",
    "        print ('\\nRandomForestClassifier.')\n",
    "        clf = RandomForestClassifier()       \n",
    "        grid_values = {'n_estimators': [20,50]} #,200,300]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'SVC_poly' in list_classifiers:\n",
    "        print ('\\nSVC_poly')\n",
    "        clf = SVC(kernel='poly')           \n",
    "        grid_values = {'C': [0.01]}# , 0.1, 1, 100, ]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'SVC_rbf' in list_classifiers:\n",
    "        print ('\\nSVC_rbf')\n",
    "        clf = SVC(kernel='rbf')\n",
    "        grid_values = {'C': [0.005, 0.01]}# , 0.02, 0.03, 0.1, 1, 100, 10000], 'gamma':[0.001, 0.01, 0.1]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'NB' in list_classifiers:\n",
    "        print ('\\nNB')\n",
    "        clf =  GaussianNB().fit(X_train_scaled, y_train)\n",
    "        train_f1 = f1_score(y_train, clf.predict(X_train_scaled))\n",
    "        print(\"train set f1= {}\".format(train_f1))\n",
    "        if not y_test is None:\n",
    "            test_f1 = f1_score(y_test, clf.predict(X_test_scaled))\n",
    "            print(\"train set f1= {}\".format(test_f1))\n",
    "\n",
    "            \n",
    "    if list_classifiers is None or 'GradientBoostingClassifier' in list_classifiers:\n",
    "        print ('\\nGradientBoostingClassifier.')\n",
    "        clf = GradientBoostingClassifier() # learning_rate = 0.03)       \n",
    "        grid_values = {'max_depth': [3,5,7]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'MLP' in list_classifiers:\n",
    "        print ('\\nMLP.')\n",
    "        clf = MLPClassifier(hidden_layer_sizes = [50]) #, 100])\n",
    "        grid_values = {'alpha' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "        run_GridSearchCV(clf,grid_values, X_train_scaled,X_test_scaled, y_train,  y_test= y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'xgboost' in list_classifiers:\n",
    "        print ('\\nxgboost.')\n",
    "        clf = XGBClassifier().fit(X_train_scaled, y_train, eval_metric = 'logloss')\n",
    "        y_predicted = clf.predict(X_test_scaled)\n",
    "        print ('f1_score  = {:.2}'.format(f1_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3d6578cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test= None):\n",
    "    print ('Running GridSearchCV.')\n",
    "    grid_clf = GridSearchCV(clf, param_grid=grid_values,scoring='roc_auc')\n",
    "    grid_clf.fit(X_train_scaled, y_train)\n",
    "    print('Grid best parameter (max.roc_auc ): ', grid_clf.best_params_) \n",
    "    print('Grid best score (roc_auc): ', grid_clf.best_score_) \n",
    "\n",
    "    if not y_test is None:\n",
    "        test_score= grid_clf.score(X_test_scaled, y_test)\n",
    "        print(\"test roc_auc= {}\".format(test_score))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e35a21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to use\n",
    "list_classifiers= [\n",
    "    'LogisticRegression',\n",
    "    'DecisionTreeClassifier',\n",
    "'RandomForestClassifier',\n",
    "    'NB',\n",
    "'GradientBoostingClassifier', \n",
    "    'MLP', \n",
    "    'xgboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855129f",
   "metadata": {},
   "source": [
    "## Import Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "695c1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283ef3a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "57b133c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "PassengerId                                                                \n",
       "1                   0       3    male  22.0      1      0   7.2500        S\n",
       "2                   1       1  female  38.0      1      0  71.2833        C\n",
       "3                   1       3  female  26.0      0      0   7.9250        S\n",
       "4                   1       1  female  35.0      1      0  53.1000        S\n",
       "5                   0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('./data/test.csv',\n",
    "                           index_col = 'PassengerId',\n",
    "                           usecols = ['PassengerId', 'Pclass', 'Sex',\n",
    "                                       'Age', 'SibSp', 'Parch','Fare', 'Embarked'])\n",
    "titanic_submission = pd.read_csv('./data/gender_submission.csv')\n",
    "titanic_train = pd.read_csv('./data/train.csv',\n",
    "                            index_col = 'PassengerId',\n",
    "                            usecols = ['PassengerId','Survived', 'Pclass', 'Sex',\n",
    "                                       'Age', 'SibSp', 'Parch','Fare', 'Embarked'])\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ca61b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d04823cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing successfully completed\n",
      "Preprocessing successfully completed\n"
     ]
    }
   ],
   "source": [
    "titanic_train = train_preprocessing(titanic_train)\n",
    "titanic_test = test_preprocessing(titanic_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0616d1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ce4de",
   "metadata": {},
   "source": [
    "# Division into train and testing sets and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8e1420d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing.\n",
      "Preprocessing successfully completed\n",
      "\n",
      "LogisticRegression.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max.roc_auc ):  {'C': 10000}\n",
      "Grid best score (roc_auc):  0.8425578349033407\n",
      "test roc_auc= 0.8740264797507789\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max.roc_auc ):  {'max_depth': 5}\n",
      "Grid best score (roc_auc):  0.8245890553474823\n",
      "test roc_auc= 0.8315160955347872\n",
      "\n",
      "RandomForestClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max.roc_auc ):  {'n_estimators': 50}\n",
      "Grid best score (roc_auc):  0.8316174384292362\n",
      "test roc_auc= 0.8570223260643822\n",
      "\n",
      "NB\n",
      "train set f1= 0.7058823529411765\n",
      "train set f1= 0.732394366197183\n",
      "\n",
      "GradientBoostingClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max.roc_auc ):  {'max_depth': 3}\n",
      "Grid best score (roc_auc):  0.8545870691938108\n",
      "test roc_auc= 0.8853842159916927\n",
      "\n",
      "MLP.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max.roc_auc ):  {'alpha': 0.1}\n",
      "Grid best score (roc_auc):  0.8508996803238376\n",
      "test roc_auc= 0.8762331256490135\n",
      "\n",
      "xgboost.\n",
      "f1_score  = 0.77\n"
     ]
    }
   ],
   "source": [
    "y = titanic_train['Survived']\n",
    "X = titanic_train.drop(columns = 'Survived')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 4381)\n",
    "\n",
    "# Normalize data\n",
    "X_train_scaled, X_test_scaled = normalize(X_train, X_test)\n",
    "\n",
    "#Running all classifiers to comparsion result\n",
    "run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test, list_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e5d144a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max.roc_auc ):  {'max_depth': 3}\n",
      "Grid best score (roc_auc):  0.8631204943448896\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier() # learning_rate = 0.03)       \n",
    "grid_values = {'max_depth': [3,5,7]}\n",
    "\n",
    "grid_clf = GridSearchCV(clf, param_grid = grid_values,scoring = 'roc_auc')\n",
    "grid_clf.fit(X, y)\n",
    "\n",
    "predict = grid_clf.predict(titanic_test)\n",
    "print('Grid best parameter (max.roc_auc ): ', grid_clf.best_params_) \n",
    "print('Grid best score (roc_auc): ', grid_clf.best_score_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2ba1f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     eval_metric='logloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, seed=42,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'n_estimators': range(60, 220, 40)},\n",
       "             scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    seed=42,\n",
    "    eval_metric = 'logloss'\n",
    ")\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "594f6f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = grid_search.predict(titanic_test)\n",
    "predict\n",
    "# print ('f1_score  = {:.2}'.format(f1_score(y, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a788bf07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows ร 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 0\n",
       "...               ...\n",
       "1305                0\n",
       "1306                1\n",
       "1307                0\n",
       "1308                0\n",
       "1309                0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'PassengerId': titanic_test.index, 'Survived': predict}\n",
    "result_df = pd.DataFrame(data = d)\n",
    "result_df.set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23049b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('camp2021.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdb16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
